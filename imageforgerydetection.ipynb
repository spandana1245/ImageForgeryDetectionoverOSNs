{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT_5sil24z01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cf3df2-f6b4-4842-b772-177030683e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision.models import resnet34\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image_size = 512\n",
        "batch_size = 4\n",
        "n_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL8QYcd05COd"
      },
      "outputs": [],
      "source": [
        "class ForgeryDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, is_train=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.is_train = is_train\n",
        "        self.transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.OneOf([\n",
        "                A.ImageCompression(quality_lower=30, quality_upper=90, p=1.0),\n",
        "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
        "            ], p=0.5)\n",
        "        ]) if is_train else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image = cv2.imread(self.image_paths[idx])[..., ::-1]  # BGR to RGB\n",
        "            mask = cv2.imread(self.mask_paths[idx], 0)  # Grayscale\n",
        "\n",
        "            # Resize if needed\n",
        "            image = cv2.resize(image, (image_size, image_size))\n",
        "            mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            if self.transform and self.is_train:\n",
        "                augmented = self.transform(image=image, mask=mask)\n",
        "                image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "            # Normalize and convert to tensor\n",
        "            image = torch.FloatTensor(image.transpose(2, 0, 1) / 255.)\n",
        "            mask = torch.FloatTensor(mask / 255.).unsqueeze(0)\n",
        "\n",
        "            return image, mask\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {self.image_paths[idx]}: {e}\")\n",
        "            dummy_image = torch.zeros((3, image_size, image_size))\n",
        "            dummy_mask = torch.zeros((1, image_size, image_size))\n",
        "            return dummy_image, dummy_mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "base_dir = \"/content/drive/MyDrive/project/ImageForensicsOSN/data/ImageForgeriesOSN_Dataset\"\n",
        "output_file = \"/content/drive/MyDrive/project/ImageForensicsOSN/data/traindso.npy\"\n",
        "\n",
        "# Initialize lists to store image and mask paths\n",
        "image_paths = []\n",
        "mask_paths = []\n",
        "\n",
        "# Define dataset\n",
        "dataset = \"dso\"\n",
        "\n",
        "# Corrected folder names\n",
        "forgeries_dir = os.path.join(base_dir, dataset, \"DSO_Facebook\")\n",
        "masks_dir = os.path.join(base_dir, dataset, \"DSO_GT\")\n",
        "\n",
        "# Supported image extensions\n",
        "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"]\n",
        "mask_extensions = [\".png\", \".tif\", \".tiff\"]\n",
        "\n",
        "# Check if directories exist\n",
        "if not os.path.exists(forgeries_dir):\n",
        "    print(f\"Error: Forgeries directory '{forgeries_dir}' not found!\")\n",
        "if not os.path.exists(masks_dir):\n",
        "    print(f\"Error: Masks directory '{masks_dir}' not found!\")\n",
        "\n",
        "# Load images and masks\n",
        "if os.path.exists(forgeries_dir) and os.path.exists(masks_dir):\n",
        "    for img_name in os.listdir(forgeries_dir):\n",
        "        img_ext = os.path.splitext(img_name)[1].lower()\n",
        "        if img_ext not in image_extensions:\n",
        "            continue  # Skip unsupported formats\n",
        "\n",
        "        # Construct image and mask paths\n",
        "        img_path = os.path.join(forgeries_dir, img_name)\n",
        "        mask_name = os.path.splitext(img_name)[0] + \"_gt\"\n",
        "        mask_path = None\n",
        "\n",
        "        # Look for a mask with a supported extension\n",
        "        for ext in mask_extensions:\n",
        "            potential_mask_path = os.path.join(masks_dir, mask_name + ext)\n",
        "            if os.path.exists(potential_mask_path):\n",
        "                mask_path = potential_mask_path\n",
        "                break\n",
        "\n",
        "        if mask_path:\n",
        "            image_paths.append(img_path)\n",
        "            mask_paths.append(mask_path)\n",
        "\n",
        "# Combine image and mask paths into pairs\n",
        "train_data = list(zip(image_paths, mask_paths))\n",
        "\n",
        "# Save to .npy file\n",
        "np.save(output_file, train_data)\n",
        "\n",
        "print(f\"traindso.npy file created at {output_file}\")\n",
        "print(f\"Total samples: {len(train_data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwOCQ538hhY",
        "outputId": "e424377e-e619-47ac-a4e1-eaee6f4c80c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traindso.npy file created at /content/drive/MyDrive/project/ImageForensicsOSN/data/traindso.npy\n",
            "Total samples: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rYWoqnE5LvZ"
      },
      "outputs": [],
      "source": [
        "class ForgeryDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use ResNet34 as backbone\n",
        "        self.backbone = resnet34(weights='DEFAULT')\n",
        "\n",
        "        # Decoder with proper upsampling to 512x512\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(32, 16, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(16, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(pred, target):\n",
        "    pred = pred.flatten()\n",
        "    target = target.flatten()\n",
        "\n",
        "    # Binarize\n",
        "    pred_bin = (pred > 0.5).astype(np.float32)\n",
        "    target_bin = (target > 0.5).astype(np.float32)\n",
        "\n",
        "    # Calculate metrics\n",
        "    tp = np.sum((pred_bin == 1) & (target_bin == 1))\n",
        "    fp = np.sum((pred_bin == 1) & (target_bin == 0))\n",
        "    fn = np.sum((pred_bin == 0) & (target_bin == 1))\n",
        "    tn = np.sum((pred_bin == 0) & (target_bin == 0))\n",
        "\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-7\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn + epsilon)\n",
        "\n",
        "    # Precision\n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "\n",
        "    # Recall\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "\n",
        "    # F1 Score\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "\n",
        "    # IoU\n",
        "    iou = tp / (tp + fp + fn + epsilon)\n",
        "\n",
        "    # AUC\n",
        "    if len(np.unique(target_bin)) > 1:\n",
        "        auc = roc_auc_score(target_bin, pred)\n",
        "    else:\n",
        "        auc = 0.5\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'iou': iou,\n",
        "        'auc': auc\n",
        "    }"
      ],
      "metadata": {
        "id": "RhqyEgl4-T2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0KWHdKD5Q5s"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Validating\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_targets.append(masks.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    preds = np.concatenate(all_preds)\n",
        "    targets = np.concatenate(all_targets)\n",
        "\n",
        "    return calculate_metrics(preds, targets)\n",
        "\n",
        "def train_model():\n",
        "    # Load data\n",
        "    data = np.load('/content/drive/MyDrive/project/ImageForensicsOSN/data/train.npy', allow_pickle=True)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_images = [item[0] for item in train_data]\n",
        "    train_masks = [item[1] for item in train_data]\n",
        "    val_images = [item[0] for item in val_data]\n",
        "    val_masks = [item[1] for item in val_data]\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = ForgeryDataset(train_images, train_masks, is_train=True)\n",
        "    val_dataset = ForgeryDataset(val_images, val_masks, is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = ForgeryDetector().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    best_metrics = {'f1': 0}\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "        # Validate\n",
        "        metrics = validate(model, val_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Metrics:\")\n",
        "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
        "        print(f\"  IoU: {metrics['iou']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['f1'] > best_metrics['f1']:\n",
        "            best_metrics = metrics\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/project/ImageForensicsOSN/best_model.pth\")\n",
        "            print(f\"New best model saved with F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(\"Best Validation Metrics:\")\n",
        "    for k, v in best_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSIlCcBz7urG",
        "outputId": "f16a4049-64cd-4341-a2c6-0b30f75e87f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-428c9884c28e>:9: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=90, p=1.0),\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 189MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [10:09<00:00,  5.40s/it]\n",
            "Validating: 100%|██████████| 29/29 [02:31<00:00,  5.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2674\n",
            "Val Metrics:\n",
            "  AUC: 0.7970\n",
            "  Accuracy: 0.9208\n",
            "  F1: 0.0003\n",
            "  IoU: 0.0001\n",
            "  Precision: 0.8020\n",
            "  Recall: 0.0001\n",
            "New best model saved with F1: 0.0003\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:27<00:00,  1.29it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1869\n",
            "Val Metrics:\n",
            "  AUC: 0.8612\n",
            "  Accuracy: 0.9352\n",
            "  F1: 0.4007\n",
            "  IoU: 0.2505\n",
            "  Precision: 0.7489\n",
            "  Recall: 0.2735\n",
            "New best model saved with F1: 0.4007\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1703\n",
            "Val Metrics:\n",
            "  AUC: 0.8875\n",
            "  Accuracy: 0.9422\n",
            "  F1: 0.5173\n",
            "  IoU: 0.3489\n",
            "  Precision: 0.7638\n",
            "  Recall: 0.3911\n",
            "New best model saved with F1: 0.5173\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:27<00:00,  1.29it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1344\n",
            "Val Metrics:\n",
            "  AUC: 0.8858\n",
            "  Accuracy: 0.9488\n",
            "  F1: 0.5893\n",
            "  IoU: 0.4178\n",
            "  Precision: 0.8068\n",
            "  Recall: 0.4642\n",
            "New best model saved with F1: 0.5893\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.28it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:21<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1299\n",
            "Val Metrics:\n",
            "  AUC: 0.9103\n",
            "  Accuracy: 0.9460\n",
            "  F1: 0.6090\n",
            "  IoU: 0.4378\n",
            "  Precision: 0.7133\n",
            "  Recall: 0.5313\n",
            "New best model saved with F1: 0.6090\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.28it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1023\n",
            "Val Metrics:\n",
            "  AUC: 0.9314\n",
            "  Accuracy: 0.9573\n",
            "  F1: 0.6931\n",
            "  IoU: 0.5304\n",
            "  Precision: 0.8033\n",
            "  Recall: 0.6095\n",
            "New best model saved with F1: 0.6931\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.28it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:19<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1031\n",
            "Val Metrics:\n",
            "  AUC: 0.9425\n",
            "  Accuracy: 0.9590\n",
            "  F1: 0.6926\n",
            "  IoU: 0.5297\n",
            "  Precision: 0.8514\n",
            "  Recall: 0.5837\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:26<00:00,  1.31it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0763\n",
            "Val Metrics:\n",
            "  AUC: 0.9556\n",
            "  Accuracy: 0.9609\n",
            "  F1: 0.7177\n",
            "  IoU: 0.5597\n",
            "  Precision: 0.8391\n",
            "  Recall: 0.6271\n",
            "New best model saved with F1: 0.7177\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.28it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0698\n",
            "Val Metrics:\n",
            "  AUC: 0.9591\n",
            "  Accuracy: 0.9638\n",
            "  F1: 0.7446\n",
            "  IoU: 0.5931\n",
            "  Precision: 0.8442\n",
            "  Recall: 0.6660\n",
            "New best model saved with F1: 0.7446\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 113/113 [01:28<00:00,  1.28it/s]\n",
            "Validating: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0676\n",
            "Val Metrics:\n",
            "  AUC: 0.9604\n",
            "  Accuracy: 0.9635\n",
            "  F1: 0.7414\n",
            "  IoU: 0.5890\n",
            "  Precision: 0.8442\n",
            "  Recall: 0.6609\n",
            "\n",
            "Training complete!\n",
            "Best Validation Metrics:\n",
            "  accuracy: 0.9638\n",
            "  precision: 0.8442\n",
            "  recall: 0.6660\n",
            "  f1: 0.7446\n",
            "  iou: 0.5931\n",
            "  auc: 0.9591\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Validating\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_targets.append(masks.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    preds = np.concatenate(all_preds)\n",
        "    targets = np.concatenate(all_targets)\n",
        "\n",
        "    return calculate_metrics(preds, targets)\n",
        "\n",
        "def train_model2():\n",
        "    # Load data\n",
        "    data = np.load('/content/drive/MyDrive/project/ImageForensicsOSN/data/traincasia.npy', allow_pickle=True)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_images = [item[0] for item in train_data]\n",
        "    train_masks = [item[1] for item in train_data]\n",
        "    val_images = [item[0] for item in val_data]\n",
        "    val_masks = [item[1] for item in val_data]\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = ForgeryDataset(train_images, train_masks, is_train=True)\n",
        "    val_dataset = ForgeryDataset(val_images, val_masks, is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = ForgeryDetector().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    best_metrics = {'f1': 0}\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "        # Validate\n",
        "        metrics = validate(model, val_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Metrics:\")\n",
        "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
        "        print(f\"  IoU: {metrics['iou']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['f1'] > best_metrics['f1']:\n",
        "            best_metrics = metrics\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/project/ImageForensicsOSN/best_modelcasia.pth\")\n",
        "            print(f\"New best model saved with F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(\"Best Validation Metrics:\")\n",
        "    for k, v in best_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "mF8_-wU5-EjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNWbcmo-2TL",
        "outputId": "5a646db2-dafb-49df-a699-18151579321e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-428c9884c28e>:9: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=90, p=1.0),\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [10:25<00:00,  3.40s/it]\n",
            "Validating: 100%|██████████| 46/46 [02:32<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2712\n",
            "Val Metrics:\n",
            "  AUC: 0.8134\n",
            "  Accuracy: 0.9109\n",
            "  F1: 0.2205\n",
            "  IoU: 0.1239\n",
            "  Precision: 0.6459\n",
            "  Recall: 0.1330\n",
            "New best model saved with F1: 0.2205\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:36<00:00,  5.10it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:04<00:00,  9.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2090\n",
            "Val Metrics:\n",
            "  AUC: 0.8510\n",
            "  Accuracy: 0.9183\n",
            "  F1: 0.3756\n",
            "  IoU: 0.2312\n",
            "  Precision: 0.6802\n",
            "  Recall: 0.2594\n",
            "New best model saved with F1: 0.3756\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:37<00:00,  4.85it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:05<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1654\n",
            "Val Metrics:\n",
            "  AUC: 0.8761\n",
            "  Accuracy: 0.9290\n",
            "  F1: 0.5040\n",
            "  IoU: 0.3369\n",
            "  Precision: 0.7458\n",
            "  Recall: 0.3806\n",
            "New best model saved with F1: 0.5040\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:38<00:00,  4.76it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:05<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1247\n",
            "Val Metrics:\n",
            "  AUC: 0.8794\n",
            "  Accuracy: 0.9260\n",
            "  F1: 0.5943\n",
            "  IoU: 0.4227\n",
            "  Precision: 0.6186\n",
            "  Recall: 0.5718\n",
            "New best model saved with F1: 0.5943\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:38<00:00,  4.77it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:04<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0983\n",
            "Val Metrics:\n",
            "  AUC: 0.9081\n",
            "  Accuracy: 0.9377\n",
            "  F1: 0.6117\n",
            "  IoU: 0.4406\n",
            "  Precision: 0.7467\n",
            "  Recall: 0.5180\n",
            "New best model saved with F1: 0.6117\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:38<00:00,  4.80it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:05<00:00,  8.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0813\n",
            "Val Metrics:\n",
            "  AUC: 0.9133\n",
            "  Accuracy: 0.9403\n",
            "  F1: 0.6374\n",
            "  IoU: 0.4678\n",
            "  Precision: 0.7513\n",
            "  Recall: 0.5535\n",
            "New best model saved with F1: 0.6374\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:38<00:00,  4.75it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:05<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0689\n",
            "Val Metrics:\n",
            "  AUC: 0.9149\n",
            "  Accuracy: 0.9419\n",
            "  F1: 0.6536\n",
            "  IoU: 0.4854\n",
            "  Precision: 0.7510\n",
            "  Recall: 0.5785\n",
            "New best model saved with F1: 0.6536\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:38<00:00,  4.78it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:04<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0558\n",
            "Val Metrics:\n",
            "  AUC: 0.9089\n",
            "  Accuracy: 0.9366\n",
            "  F1: 0.6258\n",
            "  IoU: 0.4554\n",
            "  Precision: 0.7096\n",
            "  Recall: 0.5597\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:36<00:00,  5.05it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:04<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0512\n",
            "Val Metrics:\n",
            "  AUC: 0.9215\n",
            "  Accuracy: 0.9403\n",
            "  F1: 0.6501\n",
            "  IoU: 0.4816\n",
            "  Precision: 0.7306\n",
            "  Recall: 0.5856\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 184/184 [00:36<00:00,  5.06it/s]\n",
            "Validating: 100%|██████████| 46/46 [00:05<00:00,  8.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0468\n",
            "Val Metrics:\n",
            "  AUC: 0.9223\n",
            "  Accuracy: 0.9409\n",
            "  F1: 0.6385\n",
            "  IoU: 0.4690\n",
            "  Precision: 0.7593\n",
            "  Recall: 0.5509\n",
            "\n",
            "Training complete!\n",
            "Best Validation Metrics:\n",
            "  accuracy: 0.9419\n",
            "  precision: 0.7510\n",
            "  recall: 0.5785\n",
            "  f1: 0.6536\n",
            "  iou: 0.4854\n",
            "  auc: 0.9149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Validating\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_targets.append(masks.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    preds = np.concatenate(all_preds)\n",
        "    targets = np.concatenate(all_targets)\n",
        "\n",
        "    return calculate_metrics(preds, targets)\n",
        "\n",
        "def train_model3():\n",
        "    # Load data\n",
        "    data = np.load('/content/drive/MyDrive/project/ImageForensicsOSN/data/traincolumbia.npy', allow_pickle=True)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_images = [item[0] for item in train_data]\n",
        "    train_masks = [item[1] for item in train_data]\n",
        "    val_images = [item[0] for item in val_data]\n",
        "    val_masks = [item[1] for item in val_data]\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = ForgeryDataset(train_images, train_masks, is_train=True)\n",
        "    val_dataset = ForgeryDataset(val_images, val_masks, is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = ForgeryDetector().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    best_metrics = {'f1': 0}\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "        # Validate\n",
        "        metrics = validate(model, val_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Metrics:\")\n",
        "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
        "        print(f\"  IoU: {metrics['iou']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['f1'] > best_metrics['f1']:\n",
        "            best_metrics = metrics\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/project/ImageForensicsOSN/best_modelcolumbia.pth\")\n",
        "            print(f\"New best model saved with F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(\"Best Validation Metrics:\")\n",
        "    for k, v in best_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "3c9e91jUCkjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhjtJnP3DRwG",
        "outputId": "50e7e5d8-7670-4885-bdb1-93217394e8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-428c9884c28e>:9: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=90, p=1.0),\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 198MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [02:27<00:00,  4.61s/it]\n",
            "Validating: 100%|██████████| 8/8 [00:35<00:00,  4.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4691\n",
            "Val Metrics:\n",
            "  AUC: 0.8693\n",
            "  Accuracy: 0.8183\n",
            "  F1: 0.6495\n",
            "  IoU: 0.4809\n",
            "  Precision: 0.6321\n",
            "  Recall: 0.6678\n",
            "New best model saved with F1: 0.6495\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.86it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2584\n",
            "Val Metrics:\n",
            "  AUC: 0.8969\n",
            "  Accuracy: 0.8391\n",
            "  F1: 0.6230\n",
            "  IoU: 0.4524\n",
            "  Precision: 0.7613\n",
            "  Recall: 0.5272\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.92it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1801\n",
            "Val Metrics:\n",
            "  AUC: 0.9217\n",
            "  Accuracy: 0.8647\n",
            "  F1: 0.7395\n",
            "  IoU: 0.5866\n",
            "  Precision: 0.7188\n",
            "  Recall: 0.7614\n",
            "New best model saved with F1: 0.7395\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.67it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1130\n",
            "Val Metrics:\n",
            "  AUC: 0.9180\n",
            "  Accuracy: 0.8704\n",
            "  F1: 0.7409\n",
            "  IoU: 0.5885\n",
            "  Precision: 0.7467\n",
            "  Recall: 0.7353\n",
            "New best model saved with F1: 0.7409\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.68it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0840\n",
            "Val Metrics:\n",
            "  AUC: 0.9494\n",
            "  Accuracy: 0.8684\n",
            "  F1: 0.7748\n",
            "  IoU: 0.6324\n",
            "  Precision: 0.6812\n",
            "  Recall: 0.8981\n",
            "New best model saved with F1: 0.7748\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.77it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0795\n",
            "Val Metrics:\n",
            "  AUC: 0.9481\n",
            "  Accuracy: 0.8944\n",
            "  F1: 0.7969\n",
            "  IoU: 0.6624\n",
            "  Precision: 0.7733\n",
            "  Recall: 0.8221\n",
            "New best model saved with F1: 0.7969\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0526\n",
            "Val Metrics:\n",
            "  AUC: 0.9548\n",
            "  Accuracy: 0.8881\n",
            "  F1: 0.7955\n",
            "  IoU: 0.6604\n",
            "  Precision: 0.7380\n",
            "  Recall: 0.8627\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:09<00:00,  3.29it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  5.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0463\n",
            "Val Metrics:\n",
            "  AUC: 0.9543\n",
            "  Accuracy: 0.8964\n",
            "  F1: 0.8045\n",
            "  IoU: 0.6730\n",
            "  Precision: 0.7673\n",
            "  Recall: 0.8456\n",
            "New best model saved with F1: 0.8045\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:08<00:00,  3.72it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0394\n",
            "Val Metrics:\n",
            "  AUC: 0.9546\n",
            "  Accuracy: 0.8880\n",
            "  F1: 0.7949\n",
            "  IoU: 0.6597\n",
            "  Precision: 0.7381\n",
            "  Recall: 0.8613\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 32/32 [00:09<00:00,  3.40it/s]\n",
            "Validating: 100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0403\n",
            "Val Metrics:\n",
            "  AUC: 0.9542\n",
            "  Accuracy: 0.8903\n",
            "  F1: 0.7973\n",
            "  IoU: 0.6630\n",
            "  Precision: 0.7464\n",
            "  Recall: 0.8558\n",
            "\n",
            "Training complete!\n",
            "Best Validation Metrics:\n",
            "  accuracy: 0.8964\n",
            "  precision: 0.7673\n",
            "  recall: 0.8456\n",
            "  f1: 0.8045\n",
            "  iou: 0.6730\n",
            "  auc: 0.9543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Validating\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_targets.append(masks.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    preds = np.concatenate(all_preds)\n",
        "    targets = np.concatenate(all_targets)\n",
        "\n",
        "    return calculate_metrics(preds, targets)\n",
        "\n",
        "def train_model4():\n",
        "    # Load data\n",
        "    data = np.load('/content/drive/MyDrive/project/ImageForensicsOSN/data/traindso.npy', allow_pickle=True)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_images = [item[0] for item in train_data]\n",
        "    train_masks = [item[1] for item in train_data]\n",
        "    val_images = [item[0] for item in val_data]\n",
        "    val_masks = [item[1] for item in val_data]\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = ForgeryDataset(train_images, train_masks, is_train=True)\n",
        "    val_dataset = ForgeryDataset(val_images, val_masks, is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = ForgeryDetector().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    best_metrics = {'f1': 0}\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "        # Validate\n",
        "        metrics = validate(model, val_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Metrics:\")\n",
        "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
        "        print(f\"  IoU: {metrics['iou']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['f1'] > best_metrics['f1']:\n",
        "            best_metrics = metrics\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/project/ImageForensicsOSN/best_modeldso.pth\")\n",
        "            print(f\"New best model saved with F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(\"Best Validation Metrics:\")\n",
        "    for k, v in best_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "eg2NC-L3EmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O9SvZvIFInF",
        "outputId": "1ca1641b-854d-47b9-93c7-2307a896443a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-428c9884c28e>:9: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=90, p=1.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [01:59<00:00,  5.98s/it]\n",
            "Validating: 100%|██████████| 5/5 [00:29<00:00,  5.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4088\n",
            "Val Metrics:\n",
            "  AUC: 0.8141\n",
            "  Accuracy: 0.8600\n",
            "  F1: 0.0000\n",
            "  IoU: 0.0000\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:11<00:00,  1.69it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2870\n",
            "Val Metrics:\n",
            "  AUC: 0.8065\n",
            "  Accuracy: 0.8609\n",
            "  F1: 0.0231\n",
            "  IoU: 0.0117\n",
            "  Precision: 0.6952\n",
            "  Recall: 0.0117\n",
            "New best model saved with F1: 0.0231\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:12<00:00,  1.59it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2012\n",
            "Val Metrics:\n",
            "  AUC: 0.8331\n",
            "  Accuracy: 0.8648\n",
            "  F1: 0.3771\n",
            "  IoU: 0.2324\n",
            "  Precision: 0.5310\n",
            "  Recall: 0.2923\n",
            "New best model saved with F1: 0.3771\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:14<00:00,  1.41it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1514\n",
            "Val Metrics:\n",
            "  AUC: 0.8566\n",
            "  Accuracy: 0.8757\n",
            "  F1: 0.3915\n",
            "  IoU: 0.2434\n",
            "  Precision: 0.6225\n",
            "  Recall: 0.2856\n",
            "New best model saved with F1: 0.3915\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:14<00:00,  1.41it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1214\n",
            "Val Metrics:\n",
            "  AUC: 0.8484\n",
            "  Accuracy: 0.8700\n",
            "  F1: 0.4516\n",
            "  IoU: 0.2917\n",
            "  Precision: 0.5514\n",
            "  Recall: 0.3824\n",
            "New best model saved with F1: 0.4516\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:14<00:00,  1.39it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0960\n",
            "Val Metrics:\n",
            "  AUC: 0.8641\n",
            "  Accuracy: 0.8717\n",
            "  F1: 0.4997\n",
            "  IoU: 0.3331\n",
            "  Precision: 0.5501\n",
            "  Recall: 0.4578\n",
            "New best model saved with F1: 0.4997\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:13<00:00,  1.43it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0881\n",
            "Val Metrics:\n",
            "  AUC: 0.8467\n",
            "  Accuracy: 0.8644\n",
            "  F1: 0.4720\n",
            "  IoU: 0.3089\n",
            "  Precision: 0.5187\n",
            "  Recall: 0.4330\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0746\n",
            "Val Metrics:\n",
            "  AUC: 0.8549\n",
            "  Accuracy: 0.8770\n",
            "  F1: 0.4684\n",
            "  IoU: 0.3058\n",
            "  Precision: 0.5931\n",
            "  Recall: 0.3870\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:11<00:00,  1.75it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0671\n",
            "Val Metrics:\n",
            "  AUC: 0.8571\n",
            "  Accuracy: 0.8758\n",
            "  F1: 0.4729\n",
            "  IoU: 0.3096\n",
            "  Precision: 0.5827\n",
            "  Recall: 0.3979\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 20/20 [00:11<00:00,  1.68it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0679\n",
            "Val Metrics:\n",
            "  AUC: 0.8568\n",
            "  Accuracy: 0.8743\n",
            "  F1: 0.4836\n",
            "  IoU: 0.3189\n",
            "  Precision: 0.5691\n",
            "  Recall: 0.4204\n",
            "\n",
            "Training complete!\n",
            "Best Validation Metrics:\n",
            "  accuracy: 0.8717\n",
            "  precision: 0.5501\n",
            "  recall: 0.4578\n",
            "  f1: 0.4997\n",
            "  iou: 0.3331\n",
            "  auc: 0.8641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet34\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Config - should match training config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image_size = 512\n",
        "batch_size = 4\n",
        "\n",
        "class ForgeryDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.has_masks = mask_paths is not None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image = cv2.imread(self.image_paths[idx])[..., ::-1]  # BGR to RGB\n",
        "            image = cv2.resize(image, (image_size, image_size))\n",
        "\n",
        "            # Normalize and convert to tensor\n",
        "            image = torch.FloatTensor(image.transpose(2, 0, 1) / 255)\n",
        "\n",
        "            if self.has_masks:\n",
        "                mask = cv2.imread(self.mask_paths[idx], 0)  # Grayscale\n",
        "                mask = cv2.resize(mask, (image_size, image_size))\n",
        "                # Convert to binary mask (0 or 1)\n",
        "                _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "                mask = torch.FloatTensor(mask / 255.).unsqueeze(0)\n",
        "                return image, mask, self.image_paths[idx]\n",
        "            else:\n",
        "                return image, self.image_paths[idx]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {self.image_paths[idx]}: {e}\")\n",
        "            if self.has_masks:\n",
        "                dummy_image = torch.zeros((3, image_size, image_size))\n",
        "                dummy_mask = torch.zeros((1, image_size, image_size))\n",
        "                return dummy_image, dummy_mask, self.image_paths[idx]\n",
        "            else:\n",
        "                dummy_image = torch.zeros((3, image_size, image_size))\n",
        "                return dummy_image, self.image_paths[idx]\n",
        "\n",
        "class ForgeryDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use ResNet34 as backbone\n",
        "        self.backbone = resnet34(weights=None)  # Weights will be loaded from state_dict\n",
        "\n",
        "        # Decoder with proper upsampling to 512x512\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(32, 16, 3, padding=1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(16, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "def calculate_metrics(pred, target):\n",
        "    pred = pred.flatten()\n",
        "    target = target.flatten()\n",
        "\n",
        "    # Binarize predictions\n",
        "    pred_bin = (pred > 0.5).astype(np.float32)\n",
        "    # Target is already binary (0 or 1)\n",
        "    target_bin = target.astype(np.float32)\n",
        "\n",
        "    # Calculate metrics\n",
        "    tp = np.sum((pred_bin == 1) & (target_bin == 1))\n",
        "    fp = np.sum((pred_bin == 1) & (target_bin == 0))\n",
        "    fn = np.sum((pred_bin == 0) & (target_bin == 1))\n",
        "    tn = np.sum((pred_bin == 0) & (target_bin == 0))\n",
        "\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-7\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn + epsilon)\n",
        "\n",
        "    # Precision\n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "\n",
        "    # Recall\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "\n",
        "    # F1 Score\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "\n",
        "    # IoU\n",
        "    iou = tp / (tp + fp + fn + epsilon)\n",
        "\n",
        "    # AUC\n",
        "    if len(np.unique(target_bin)) > 1:\n",
        "        auc = roc_auc_score(target_bin, pred)\n",
        "    else:\n",
        "        auc = 0.5\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'iou': iou,\n",
        "        'auc': auc\n",
        "    }\n",
        "\n",
        "def visualize_results(image, pred_mask, true_mask=None, save_path=None):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted Mask (show as binary)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow((pred_mask > 0.5).astype(np.uint8), cmap='gray')\n",
        "    plt.title(\"Predicted Binary Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # True Mask (if available, show as binary)\n",
        "    if true_mask is not None:\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title(\"True Binary Mask\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def test_model(model_path, test_images, test_masks=None, output_dir='results'):\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load model\n",
        "    model = ForgeryDetector().to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Create dataset and loader\n",
        "    has_masks = test_masks is not None\n",
        "    test_dataset = ForgeryDataset(test_images, test_masks)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_image_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            if has_masks:\n",
        "                images, masks, paths = batch\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                all_targets.append(masks.cpu().numpy())\n",
        "            else:\n",
        "                images, paths = batch\n",
        "                images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            all_preds.append(outputs.cpu().numpy())\n",
        "            all_image_paths.extend(paths)\n",
        "\n",
        "    # Process results\n",
        "    preds = np.concatenate(all_preds)\n",
        "\n",
        "    # Save and visualize results\n",
        "    for i in range(len(preds)):\n",
        "        image_path = all_image_paths[i]\n",
        "        image_name = os.path.basename(image_path)\n",
        "\n",
        "        # Get original image\n",
        "        orig_image = cv2.imread(image_path)[..., ::-1]\n",
        "        orig_image = cv2.resize(orig_image, (image_size, image_size))\n",
        "\n",
        "        # Get predicted mask\n",
        "        pred_mask = preds[i][0]  # Remove batch and channel dim\n",
        "\n",
        "        # Get true mask if available\n",
        "        true_mask = None\n",
        "        if has_masks:\n",
        "            true_mask = all_targets[i][0]\n",
        "\n",
        "        # Visualize and save\n",
        "        save_path = os.path.join(output_dir, f\"result_{image_name}\")\n",
        "        visualize_results(orig_image, pred_mask, true_mask, save_path)\n",
        "\n",
        "    # Calculate metrics if masks are available\n",
        "    if has_masks:\n",
        "        targets = np.concatenate(all_targets)\n",
        "        metrics = calculate_metrics(preds, targets)\n",
        "\n",
        "        print(\"\\nTest Metrics:\")\n",
        "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1: {metrics['f1']:.4f}\")\n",
        "        print(f\"  IoU: {metrics['iou']:.4f}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "        return metrics\n",
        "    else:\n",
        "        print(f\"\\nInference complete! Results saved to {output_dir}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your test data\n",
        "    test_images = [\"/content/drive/MyDrive/project/ImageForensicsOSN/data/ImageForgeriesOSN_Dataset/nist16/NIST16_Facebook/000001.jpg\"]\n",
        "    test_masks = None\n",
        "\n",
        "    # Test the model\n",
        "    test_model(\n",
        "        model_path=\"/content/drive/MyDrive/project/ImageForensicsOSN/best_model.pth\",  # Path to your saved model\n",
        "        test_images=test_images,\n",
        "        test_masks=test_masks,\n",
        "        output_dir=\"/content/drive/MyDrive/project/ImageForensicsOSN/test_results\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLeq7W_iQtly",
        "outputId": "74091b14-9ffe-4d5c-9a0e-860161fd1f46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference complete! Results saved to /content/drive/MyDrive/project/ImageForensicsOSN/test_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1AFAhR1kN_BE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}